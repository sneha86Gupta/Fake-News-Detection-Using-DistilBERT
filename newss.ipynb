{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZmGTsUfYHIm",
        "outputId": "48385fe5-8913-40c4-f5ed-d5be81e6588b",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=9e96365111a20adaaa2a8a18238f77f619fce12613d9124ed0b127b72cc4feb9\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ],
      "source": [
        "# STEP 1: Install dependencies\n",
        "!pip install pandas tqdm wget\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import wget\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# Create a data directory\n",
        "os.makedirs(\"data\", exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load datasets\n",
        "df_news = pd.read_csv(\"/content/news_dataset.csv\")\n",
        "df_pol_real = pd.read_csv(\"/content/politifact_real.csv\")\n",
        "df_pol_fake = pd.read_csv(\"/content/politifact_fake.csv\")\n",
        "df_gos_real = pd.read_csv(\"/content/gossipcop_real.csv\")\n",
        "df_gos_fake = pd.read_csv(\"/content/gossipcop_fake.csv\")\n",
        "\n",
        "# news_dataset.csv is already in correct format\n",
        "df_news_clean = df_news[['text', 'label']]\n",
        "\n",
        "# Politifact real â€” use 'title' column as text\n",
        "df_pol_real_clean = df_pol_real[['title']].rename(columns={'title': 'text'})\n",
        "df_pol_real_clean['label'] = 'REAL'\n",
        "\n",
        "# Politifact fake\n",
        "df_pol_fake_clean = df_pol_fake[['title']].rename(columns={'title': 'text'})\n",
        "df_pol_fake_clean['label'] = 'FAKE'\n",
        "\n",
        "# Gossipcop real\n",
        "df_gos_real_clean = df_gos_real[['title']].rename(columns={'title': 'text'})\n",
        "df_gos_real_clean['label'] = 'REAL'\n",
        "\n",
        "# Gossipcop fake\n",
        "df_gos_fake_clean = df_gos_fake[['title']].rename(columns={'title': 'text'})\n",
        "df_gos_fake_clean['label'] = 'FAKE'\n",
        "\n",
        "# Combine all\n",
        "df_final = pd.concat([\n",
        "    df_news_clean,\n",
        "    df_pol_real_clean,\n",
        "    df_pol_fake_clean,\n",
        "    df_gos_real_clean,\n",
        "    df_gos_fake_clean\n",
        "], ignore_index=True)\n",
        "\n",
        "# Remove missing or empty texts\n",
        "df_final.dropna(subset=['text'], inplace=True)\n",
        "df_final = df_final[df_final['text'].str.strip() != '']\n",
        "\n",
        "# Shuffle\n",
        "df_final = df_final.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Save\n",
        "df_final.to_csv(\"/content/fake_news_combined.csv\", index=False)\n",
        "\n",
        "# Summary\n",
        "print(\"âœ… Combined dataset created and saved as 'fake_news_combined.csv'\")\n",
        "print(\"ðŸ“Š Total samples:\", len(df_final))\n",
        "print(\"ðŸ”¢ Label distribution:\\n\", df_final['label'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNgz_-7YYRxb",
        "outputId": "d974e265-515d-4135-d92f-c96757ad0ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Combined dataset created and saved as 'fake_news_combined.csv'\n",
            "ðŸ“Š Total samples: 26917\n",
            "ðŸ”¢ Label distribution:\n",
            " label\n",
            "REAL    19291\n",
            "FAKE     7626\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "-VuevruGisQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjEfGl9livFX",
        "outputId": "67a829d3-603f-4537-98f3-aa3ecba8549b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the combined CSV correctly\n",
        "df = pd.read_csv('/content/fake_news_combined.csv')\n",
        "\n",
        "# Clean the text column\n",
        "df['text'] = df['text'].astype(str)\n",
        "\n",
        "# Define the cleaning function (if not already defined)\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
        "    text = re.sub(r'\\@\\w+|\\#', '', text)\n",
        "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
        "    text = text.lower()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    return \" \".join(words)\n",
        "\n",
        "# Apply cleaning\n",
        "df['clean_text'] = df['text'].apply(clean_text)\n",
        "\n",
        "# Save cleaned file\n",
        "df.to_csv('/content/fake_news_preprocessed.csv', index=False)\n",
        "print(\"âœ… Preprocessed file saved as 'fake_news_preprocessed.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yj2VyZMdjWS_",
        "outputId": "878d7d0e-7152-4aa6-fd5c-f2198d4b28f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Preprocessed file saved as 'fake_news_preprocessed.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload preprocessed data\n",
        "df = pd.read_csv('/content/fake_news_preprocessed.csv')\n",
        "\n",
        "# Normalize labels\n",
        "df['label'] = df['label'].replace({\n",
        "    'FAKE': 0,\n",
        "    'REAL': 1\n",
        "}).astype(int)\n",
        "\n",
        "print(df['label'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3XgXUC2jthd",
        "outputId": "fc61cdcb-2a97-4ff9-ad5e-306711569dff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "1    19291\n",
            "0     7626\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-78-495533020.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df['label'] = df['label'].replace({\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Optional: install xgboost if not installed\n",
        "# !pip install xgboost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/fake_news_preprocessed.csv')\n",
        "\n",
        "# Replace labels and convert to int\n",
        "df['label'] = df['label'].replace({'FAKE': 0, 'REAL': 1}).astype(int)\n",
        "\n",
        "# Handle missing values in text column\n",
        "df = df.dropna(subset=['clean_text'])\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['clean_text'], df['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# TF-IDF vectorization\n",
        "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Calculate scale_pos_weight for XGBoost\n",
        "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
        "\n",
        "def evaluate_model(name, model):\n",
        "    print(f\"\\n{'='*20} {name} {'='*20}\")\n",
        "    model.fit(X_train_tfidf, y_train)\n",
        "    y_pred = model.predict(X_test_tfidf)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"{name} Accuracy: {acc * 100:.2f}%\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
        "evaluate_model(\"Logistic Regression\", lr)\n",
        "\n",
        "# Linear SVM\n",
        "svm = LinearSVC(class_weight='balanced', max_iter=5000)\n",
        "evaluate_model(\"Linear SVM\", svm)\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestClassifier(class_weight='balanced', n_estimators=100, random_state=42)\n",
        "evaluate_model(\"Random Forest\", rf)\n",
        "\n",
        "# XGBoost\n",
        "xgb = XGBClassifier(\n",
        "    use_label_encoder=False, eval_metric='logloss',\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    n_estimators=100, random_state=42)\n",
        "evaluate_model(\"XGBoost\", xgb)\n",
        "\n",
        "# Decision Tree\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "evaluate_model(\"Decision Tree\", dt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU4mbErp9Suj",
        "outputId": "a41a25a1-56c9-4c24-915e-0c4f077929d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-87-1064757680.py:19: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df['label'] = df['label'].replace({'FAKE': 0, 'REAL': 1}).astype(int)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================== Logistic Regression ====================\n",
            "Logistic Regression Accuracy: 82.31%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.77      0.71      1531\n",
            "           1       0.90      0.84      0.87      3852\n",
            "\n",
            "    accuracy                           0.82      5383\n",
            "   macro avg       0.78      0.81      0.79      5383\n",
            "weighted avg       0.83      0.82      0.83      5383\n",
            "\n",
            "\n",
            "==================== Linear SVM ====================\n",
            "Linear SVM Accuracy: 81.76%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.77      0.71      1531\n",
            "           1       0.90      0.84      0.87      3852\n",
            "\n",
            "    accuracy                           0.82      5383\n",
            "   macro avg       0.78      0.80      0.79      5383\n",
            "weighted avg       0.83      0.82      0.82      5383\n",
            "\n",
            "\n",
            "==================== Random Forest ====================\n",
            "Random Forest Accuracy: 84.56%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.65      0.71      1531\n",
            "           1       0.87      0.92      0.90      3852\n",
            "\n",
            "    accuracy                           0.85      5383\n",
            "   macro avg       0.82      0.79      0.80      5383\n",
            "weighted avg       0.84      0.85      0.84      5383\n",
            "\n",
            "\n",
            "==================== XGBoost ====================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:46:57] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Accuracy: 83.76%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.71      0.71      1531\n",
            "           1       0.89      0.89      0.89      3852\n",
            "\n",
            "    accuracy                           0.84      5383\n",
            "   macro avg       0.80      0.80      0.80      5383\n",
            "weighted avg       0.84      0.84      0.84      5383\n",
            "\n",
            "\n",
            "==================== Decision Tree ====================\n",
            "Decision Tree Accuracy: 81.42%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.66      0.67      1531\n",
            "           1       0.86      0.88      0.87      3852\n",
            "\n",
            "    accuracy                           0.81      5383\n",
            "   macro avg       0.77      0.77      0.77      5383\n",
            "weighted avg       0.81      0.81      0.81      5383\n",
            "\n"
          ]
        }
      ]
    }
  ]
}